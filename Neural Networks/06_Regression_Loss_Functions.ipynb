{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usuqSECUhPcg"
      },
      "source": [
        "<h1 style=\"font-size:30px;\">Regression Loss Functions</h1>\n",
        "\n",
        "In this notebook, we will explore the common loss functions used for Regression tasks in Deep Learning. Commonly, there are two important Regression loss functions. They are:\n",
        "1. Mean Squared Error\n",
        "2. Mean Absolute Error\n",
        "\n",
        "First, we will implement the above two from scratch using the low level functionalities of PyTorch. Then we will see what are the API methods that pyTorch provides to calculate these losses with just one line of code.\n",
        "\n",
        "<img src='https://learnopencv.com/wp-content/uploads/2022/01/c4_02_mse_vs_mae.png' width=800 align='center'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFHGnh5LW5LW"
      },
      "source": [
        "## Table of Cotents\n",
        "* [1 Mean Squared Error (MSE)](#1-Mean-Squared-Error-%28MSE%29)\n",
        "* [2 Mean Absolute Error (MAE)](#2-Mean-Absolute-Error-%28MAE%29)\n",
        "* [3 Using torch.nn.functional](#3-Using-torch.nn.functional)\n",
        "    * [3.1 PyTorch Mean Squared Error](#3.1-PyTorch-Mean-Squared-Error)\n",
        "    * [3.2 PyTorch Mean Absolute Error](#3.2-PyTorch-Mean-Absolute-Error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21ttYsHBhPcj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YF7mInEHC66"
      },
      "outputs": [],
      "source": [
        "bold = f\"\\033[1m\"\n",
        "reset = f\"\\033[0m\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfWfgCbLhPck"
      },
      "source": [
        "## 1 Mean Squared Error (MSE)\n",
        "Just like any other loss function, or error function calculation, here also, we need the true values and the predicted values. The following is the mathematical formula to calculate MSE:\n",
        "$$\n",
        "MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2\n",
        "$$\n",
        "where\n",
        "\n",
        "$n$: number of examples or samples.\n",
        "\n",
        "$y$: true values.\n",
        "\n",
        "$\\hat{y}$: predicted values.\n",
        "\n",
        "Here, we take a mean of the squared difference between the groud truth and predicted values, that's why the name, Mean Squared Error. As this is an error function, we would like this value to be as small as possible. A smaller value indicates that the ground truth and predicted values are closer to each other.\n",
        "\n",
        "However, there is a disadvantage to use MSE:\n",
        "* It is senstive to outliers.\n",
        "\n",
        "In the following `mse_loss()` function we calculate the MSE.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISmW6_5bhPck"
      },
      "outputs": [],
      "source": [
        "def mse_loss(y_pred, y_true):\n",
        "    # Convert inputs to PyTorch Tensor first.\n",
        "    y_pred = torch.from_numpy(y_pred)\n",
        "    y_true = torch.from_numpy(y_true)\n",
        "\n",
        "    mse_loss = ((y_true - y_pred)**2).mean()\n",
        "    return mse_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz_7F94jhPcl",
        "outputId": "0948fb8f-faf6-4d4c-9e32-67e00eda488d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE): \u001b[1m0.50\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "y_true = np.array([0., 1., 0., 0.])\n",
        "y_pred = np.array([1., 1., 1., 0.])\n",
        "\n",
        "mse = mse_loss(y_true, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {bold}{mse:.2f}{reset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8gEJm8ahPcm"
      },
      "source": [
        "## 2 Mean Absolute Error (MAE)\n",
        "MAE is another common way to calculate the error between the true values and the predicted values. Here, instead of squaring the error we average the error over the absolute value of the difference between the true and predicted values.\n",
        "\n",
        "$$\n",
        "MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y_i}|\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "$n$: number of examples or samples.\n",
        "\n",
        "$y$: true values.\n",
        "\n",
        "$\\hat{y}$: predicted values.\n",
        "\n",
        "Here also, a lower value indicates a better model.\n",
        "\n",
        "It overcomes the disadvantage of MSE:\n",
        "* Less sensitive to outliers compared to MSE.\n",
        "\n",
        "Similar to the previous function, we calculate the MAE in the following code block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs7JpKBthPcm"
      },
      "outputs": [],
      "source": [
        "def mae_loss(y_pred, y_true):\n",
        "    # Convert inputs to Pytorch Tensor first.\n",
        "    y_pred = torch.from_numpy(y_pred)\n",
        "    y_true = torch.from_numpy(y_true)\n",
        "\n",
        "    mae_loss = torch.abs(y_true - y_pred).mean()\n",
        "    return mae_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc3KgH_chPcm",
        "outputId": "b1f07793-dfb5-4d4f-dd4b-58a106357c6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (MAE): \u001b[1m1.75\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "y_true = np.array([0., 2., 0., 3.])\n",
        "y_pred = np.array([1., 1., 2., 0.])\n",
        "\n",
        "mae = mae_loss(y_true, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {bold}{mae:.2f}{reset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi6utSbAhPcn"
      },
      "source": [
        "## 3 Using `torch.nn.functional`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVKwI09ThPcn"
      },
      "source": [
        "Pytorch already provides the implementation of loss functions through it's `torch.nn.functional` module. Instead of writing a function, defining the tensors, and then calculating the losses, we can just call the functions directly with just one line of code.\n",
        "\n",
        "Now, let's use the same values we used in the above cases, call the predefined PyTorch loss functions and check whether we get the same answer or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxX5D8VnhPcn"
      },
      "source": [
        "### 3.1 PyTorch Mean Squared Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RAn7BEshPcn",
        "outputId": "fb6a8a34-1d4d-45f2-ebbd-d268d7ed2939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE): \u001b[1m0.50\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "y_true = torch.tensor([0., 1., 0., 0.])\n",
        "y_pred = torch.tensor([1., 1., 1., 0.])\n",
        "\n",
        "pt_mse = F.mse_loss(y_pred, y_true)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {bold}{pt_mse:.2f}{reset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMz3bNSVhPco"
      },
      "source": [
        "You can see, we get the same answer for MSE loss but with much less code this time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiX-ktsOhPco"
      },
      "source": [
        "### 3.2 PyTorch Mean Absolute Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wHID-wbhPco",
        "outputId": "0d6862fe-1f04-4098-c589-6077f3cc5861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (MAE): \u001b[1m1.75\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "y_true = torch.tensor([0., 2., 0., 3.])\n",
        "y_pred = torch.tensor([1., 1., 2., 0.])\n",
        "\n",
        "pt_mae = F.l1_loss(y_pred, y_true)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {bold}{pt_mae:.2f}{reset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fdm1iZ1JhPco"
      },
      "source": [
        "The answer is same for Mean Absolute Error as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVeRNufEhPcp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py38-pt-metal",
      "language": "python",
      "name": "py38-pt-metal"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "325.198px"
      },
      "toc_section_display": false,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "415.828px",
        "left": "909.036px",
        "right": "20px",
        "top": "98.9838px",
        "width": "326.98px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}