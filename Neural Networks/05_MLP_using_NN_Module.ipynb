{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2cvA6soQQFV"
      },
      "source": [
        "# MLP with Single Hidden Layer using PyTorch\n",
        "\n",
        "1. Define an MLP with variable number of inputs (num_inputs), outputs (num_outputs), and nodes in hidden layer (num_hidden_layer_nodes).  \n",
        "2. Use ReLU activation for each node\n",
        "3. Use MSE loss\n",
        "4. Use SGD optimizer\n",
        "\n",
        "\n",
        "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/01/mlp.png\" alt=\"mlp\" width=\"500\"/>\n",
        "\n",
        "## Table of Contents\n",
        "* [1 Define MLP using NN Module](#1-Define-MLP-using-NN-Module)\n",
        "* [2 Generate Data](#2-Generate-Data)\n",
        "* [3 Perform Training](#3-Perform-Training)\n",
        "* [4 MLP with Sequential Module](#4-MLP-with-Sequential-Module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9bB7clYcHqb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S-GdRc31ZKd"
      },
      "outputs": [],
      "source": [
        "def system_config(SEED_VALUE=42, package_list=None):\n",
        "    \"\"\"\n",
        "    Configures the system environment for PyTorch-based operations.\n",
        "\n",
        "    Args:\n",
        "        SEED_VALUE (int): Seed value for random number generation. Default is 42.\n",
        "        package_list (str): String containing a list of additional packages to install\n",
        "        for Google Colab or Kaggle. Default is None.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the device name as a string and a boolean indicating GPU availability.\n",
        "    \"\"\"\n",
        "\n",
        "    random.seed(SEED_VALUE)\n",
        "    np.random.seed(SEED_VALUE)\n",
        "    torch.manual_seed(SEED_VALUE)\n",
        "\n",
        "    def is_running_in_colab():\n",
        "        return 'COLAB_GPU' in os.environ\n",
        "\n",
        "    def is_running_in_kaggle():\n",
        "        return 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
        "\n",
        "    #--------------------------------\n",
        "    # Check for the availability GPUs.\n",
        "    #--------------------------------\n",
        "    if torch.cuda.is_available():\n",
        "        print('Using CUDA GPU')\n",
        "\n",
        "        # This section for installing packages required by Colab.\n",
        "        if is_running_in_colab() or is_running_in_kaggle():\n",
        "            print('Installing required packages...')\n",
        "            !pip install {package_list}\n",
        "\n",
        "        # Set the device to the first CUDA device.\n",
        "        DEVICE = torch.device('cuda')\n",
        "        print(\"Device: \", DEVICE)\n",
        "        GPU_AVAILABLE = True\n",
        "\n",
        "        torch.cuda.manual_seed(SEED_VALUE)\n",
        "        torch.cuda.manual_seed_all(SEED_VALUE)\n",
        "\n",
        "        # Performance and deterministic behavior.\n",
        "        torch.backends.cudnn.enabled = True       # Provides highly optimized primitives for DL operations.\n",
        "        torch.backends.cudnn.deterministic = True # Insures deterministic even when above cudnn is enabled.\n",
        "        torch.backends.cudnn.benchmark = False    # Setting to True can cause non-deterministic behavior.\n",
        "\n",
        "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "        print('Using Apple Silicon GPU')\n",
        "\n",
        "        # Set the device to the Apple Silicon GPU Metal Performance Shader (MPS).\n",
        "        DEVICE = torch.device(\"mps\")\n",
        "        print(\"Device: \", DEVICE)\n",
        "        # Environment variable that allows PyTorch to fall back to CPU execution\n",
        "        # when encountering operations that are not currently supported by MPS.\n",
        "        os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
        "        GPU_AVAILABLE = True\n",
        "\n",
        "        torch.mps.manual_seed(SEED_VALUE)\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "\n",
        "    else:\n",
        "        print('Using CPU')\n",
        "        DEVICE = torch.device('cpu')\n",
        "        print(\"Device: \", DEVICE)\n",
        "        GPU_AVAILABLE = False\n",
        "\n",
        "        if is_running_in_colab() or is_running_in_kaggle():\n",
        "            print('Installing required packages...')\n",
        "            !pip install {package_list}\n",
        "            print('Note: Change runtime type to GPU for better performance.')\n",
        "\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "\n",
        "    return str(DEVICE), GPU_AVAILABLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvFiIeer1ZKf",
        "outputId": "294aa9bc-66e5-4545-8455-b33b7d7b7526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA GPU\n",
            "Installing required packages...\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "# Additional packages required for Google Colab or Kaggle.\n",
        "package_list = \"torchinfo\"\n",
        "\n",
        "DEVICE, GPU_AVAILABLE = system_config(package_list=package_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPyTXeGJQcuY"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yyvvvnqcHqc"
      },
      "outputs": [],
      "source": [
        "bold = f\"\\033[1m\"\n",
        "reset = f\"\\033[0m\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRdLjBkicHqd"
      },
      "source": [
        "## 1 Define MLP using NN Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bM35cGTPcHqd"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, num_inputs, num_hidden_layer_nodes, num_outputs):\n",
        "        # Initialize super class.\n",
        "        super().__init__()\n",
        "\n",
        "        # Add hidden layer.\n",
        "        self.linear1 = nn.Linear(num_inputs, num_hidden_layer_nodes)\n",
        "\n",
        "        # Add output layer.\n",
        "        self.linear2 = nn.Linear(num_hidden_layer_nodes, num_outputs)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through hidden layer with\n",
        "        x = F.relu(self.linear1(x))\n",
        "\n",
        "        # Foward pass to output layer\n",
        "        return self.linear2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2964pzZtcHqd"
      },
      "source": [
        "## 2 Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kg_zAYXqcHqd"
      },
      "outputs": [],
      "source": [
        "# Num data points.\n",
        "num_data = 1000\n",
        "\n",
        "# Data parameters.\n",
        "num_inputs = 1000\n",
        "num_outputs = 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs.\n",
        "X = torch.randn(num_data, num_inputs)\n",
        "Y = torch.randn(num_data, num_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dHknD7cHqe"
      },
      "source": [
        "## 3 Perform Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyjPulcDSJQo"
      },
      "outputs": [],
      "source": [
        "def train(model, criterion, optimizer, data, targets, num_epochs):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch_idx in range(num_epochs):\n",
        "        # Clear cell outputs at the start of each epoch.\n",
        "        clear_output()\n",
        "\n",
        "        # Zero gradients, perform a backward pass, and update the weights.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: Compute predicted y by passing data to the model.\n",
        "        y_pred = model(data)\n",
        "\n",
        "        # Compute and print loss\n",
        "        loss = loss_function(y_pred, targets)\n",
        "\n",
        "        # Calculate gradient using backward pass.\n",
        "        loss.backward()\n",
        "\n",
        "        # Update model parameters (weights).\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"{f'{bold}[ Epoch: {epoch_idx+1} ]{reset}':=^80}\")\n",
        "\n",
        "        train_loss_stat = f\"{bold}Loss: {loss:.4f}{reset}\"\n",
        "\n",
        "        print(f\"\\n{train_loss_stat}\")\n",
        "\n",
        "        print(f\"{'='*72}\\n\")\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QxgQEfocHqe"
      },
      "source": [
        "### 3.1 Define Model Parameters, Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hArzrxHWcHqe",
        "outputId": "642f4bc1-dc0e-4693-a1e2-952e23a22086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type (var_name))                  Output Shape              Param #\n",
            "==========================================================================================\n",
            "MLP (MLP)                                [1, 10]                   --\n",
            "├─Linear (linear1)                       [1, 100]                  100,100\n",
            "├─Linear (linear2)                       [1, 10]                   1,010\n",
            "==========================================================================================\n",
            "Total params: 101,110\n",
            "Trainable params: 101,110\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.10\n",
            "==========================================================================================\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.40\n",
            "Estimated Total Size (MB): 0.41\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Training parameters.\n",
        "num_epochs = 100\n",
        "\n",
        "# Network parameters.\n",
        "num_hidden_layer_nodes = 100\n",
        "\n",
        "# Get reproducible results\n",
        "torch.manual_seed(42);\n",
        "\n",
        "# Construct our model by instantiating the class defined above\n",
        "model = MLP(num_inputs, num_hidden_layer_nodes, num_outputs)\n",
        "\n",
        "print(summary(model, input_size=(1,num_inputs), device=\"cpu\", row_settings=[\"var_names\"]))\n",
        "\n",
        "# Define loss function\n",
        "loss_function = nn.MSELoss(reduction='sum')\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u6WtQD2cHqe",
        "outputId": "88c1851b-6cfb-4fec-f742-1ee7199e8be7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================\u001b[1m[ Epoch: 100 ]\u001b[0m=============================\n",
            "\n",
            "\u001b[1mLoss: 0.9612\u001b[0m\n",
            "========================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train(model, loss_function, optimizer, data=X, targets=Y, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf7lx05WcHqe"
      },
      "source": [
        "## 4 MLP with Sequential Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4pqNsMGcHqe"
      },
      "source": [
        "Observe that in the section above, we had defined the `Linear` and the `ReLU` modules individually.\n",
        "\n",
        "The value a `Sequential` module provides over manually calling a sequence of modules is that it allows treating the whole container as a single module, such that performing a transformation on the Sequential applies to each of the modules it stores.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48-dIXJ_cHqe"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "class MLP_Sequential(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_hidden_layer_nodes, num_outputs):\n",
        "        # Initialize super class\n",
        "        super().__init__()\n",
        "\n",
        "        # Build model using Sequential container.\n",
        "        self.model = nn.Sequential(\n",
        "            # Add hidden layer.\n",
        "            nn.Linear(num_inputs, num_hidden_layer_nodes),\n",
        "            # Add ReLU activation.\n",
        "            nn.ReLU(),\n",
        "            # Add output layer.\n",
        "            nn.Linear(num_hidden_layer_nodes, num_outputs)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass.\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tepPugyHcHqe"
      },
      "source": [
        "We are going to use the same training parameters that we have defined in the previous sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76vdh3e3cHqf",
        "outputId": "c9689e46-bbd7-4b8f-8581-13f3686032c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type (var_name))                  Output Shape              Param #\n",
            "==========================================================================================\n",
            "MLP_Sequential (MLP_Sequential)          [1, 10]                   --\n",
            "├─Sequential (model)                     [1, 10]                   --\n",
            "│    └─Linear (0)                        [1, 100]                  100,100\n",
            "│    └─ReLU (1)                          [1, 100]                  --\n",
            "│    └─Linear (2)                        [1, 10]                   1,010\n",
            "==========================================================================================\n",
            "Total params: 101,110\n",
            "Trainable params: 101,110\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.10\n",
            "==========================================================================================\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.40\n",
            "Estimated Total Size (MB): 0.41\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Training parameters.\n",
        "num_epochs = 100\n",
        "\n",
        "# Network parameters.\n",
        "num_hidden_layer_nodes = 100\n",
        "\n",
        "# Get reproducible results\n",
        "torch.manual_seed(42);\n",
        "\n",
        "# Construct our model by instantiating the class defined above\n",
        "model_seq = MLP_Sequential(num_inputs, num_hidden_layer_nodes, num_outputs)\n",
        "\n",
        "print(summary(model_seq, input_size=(1,num_inputs), device=\"cpu\", row_settings=[\"var_names\"]))\n",
        "\n",
        "# Define loss function\n",
        "loss_function = nn.MSELoss(reduction='sum')\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = optim.SGD(model_seq.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjzvozi8cHqf",
        "outputId": "32c4d0cd-e9ed-4b60-b133-4d8c72eecfd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================\u001b[1m[ Epoch: 100 ]\u001b[0m=============================\n",
            "\n",
            "\u001b[1mLoss: 0.9612\u001b[0m\n",
            "========================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train(model_seq, loss_function, optimizer, data=X, targets=Y, num_epochs=num_epochs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "py38-pt-metal",
      "language": "python",
      "name": "py38-pt-metal"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}